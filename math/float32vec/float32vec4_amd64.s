TEXT ·f32v4_add(SB), $0-24
	MOVQ a+0(FP), AX
	MOVQ b+8(FP), BX
	MOVQ result+16(FP), CX
	MOVAPS 0(AX), X0
	MOVAPS 0(BX), X1
	ADDPS X1, X0
	MOVAPS X0, 0(CX)
	RET

TEXT ·f32v4_sub(SB), $0-24
	MOVQ a+0(FP), AX
	MOVQ b+8(FP), BX
	MOVQ result+16(FP), CX
	MOVAPS 0(AX), X0
	MOVAPS 0(BX), X1
	SUBPS X1, X0
	MOVAPS X0, 0(CX)
	RET

TEXT ·f32v4_mul(SB), $0-24
	MOVQ a+0(FP), AX
	MOVQ b+8(FP), BX
	MOVQ result+16(FP), CX
	MOVAPS 0(AX), X0
	MOVAPS 0(BX), X1
	MULPS X1, X0
	MOVAPS X0, 0(CX)
	RET

TEXT ·f32v4_fmaFMA(SB), $0-32
	MOVQ a+0(FP), AX
	MOVQ b+8(FP), BX
	MOVQ c+16(FP), CX
	MOVQ result+24(FP), DX
	MOVAPS 0(AX), X0
	MOVAPS 0(BX), X1
	MOVAPS 0(CX), X2
	VFMADD132PS X0, X1, X2
	MOVAPS X2, 0(DX)
	RET

TEXT ·f32v4_div(SB), $0-24
	MOVQ a+0(FP), AX
	MOVQ b+8(FP), BX
	MOVQ result+16(FP), CX
	MOVAPS 0(AX), X0
	MOVAPS 0(BX), X1
	DIVPS X1, X0
	MOVAPS X0, 0(CX)
	RET

TEXT ·f32v4_min(SB), $0-24
	MOVQ v+0(FP), AX
	MOVQ mn+8(FP), BX
	MOVQ result+16(FP), CX
	MOVAPS 0(AX), X0
	MOVAPS 0(BX), X1
	MINPS X1, X0
	MOVAPS X0, 0(CX)
	RET

TEXT ·f32v4_max(SB), $0-24
	MOVQ v+0(FP), AX
	MOVQ mx+8(FP), BX
	MOVQ result+16(FP), CX
	MOVAPS 0(AX), X0
	MOVAPS 0(BX), X1
	MAXPS X1, X0
	MOVAPS X0, 0(CX)
	RET

TEXT ·f32v4_clamp(SB), $0-32
	MOVQ v+0(FP), AX
	MOVQ mn+8(FP), BX
	MOVQ mx+16(FP), CX
	MOVQ result+24(FP), DX
	MOVAPS 0(AX), X0
	MOVAPS 0(BX), X1
	MOVAPS 0(CX), X2
	MAXPS X1, X0
	MINPS X2, X0
	MOVAPS X0, 0(DX)
	RET

TEXT ·f32v4_ceilSSE41(SB), $0-24
	MOVQ v+0(FP), AX
	MOVQ result+8(FP), BX
	MOVAPS 0(AX), X0
	ROUNDPS $10, X0, X1
	MOVAPS X1, 0(BX)
	RET

TEXT ·f32v4_roundSSE41(SB), $0-24
	MOVQ v+0(FP), AX
	MOVQ result+8(FP), BX
	MOVAPS 0(AX), X0
	ROUNDPS $00, X0, X1
	MOVAPS X1, 0(BX)
	RET

TEXT ·f32v4_floorSSE41(SB), $0-24
	MOVQ v+0(FP), AX
	MOVQ result+8(FP), BX
	MOVAPS 0(AX), X0
	ROUNDPS $01, X0, X1
	MOVAPS X1, 0(BX)
	RET
